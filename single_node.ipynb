{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:44:49 WARN Utils: Your hostname, mario-hpprobook450g5 resolves to a loopback address: 127.0.1.1; using 141.47.138.65 instead (on interface wlp3s0)\n",
      "23/02/03 03:44:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:44:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://141.47.138.65:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BigData</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f524a5fb490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up von Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder.appName(\"BigData\").config('spark.executor.memory', '8g').config('spark.driver.memory', '8g').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, udf, to_timestamp, year, month\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType, DateType, StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc.setJobGroup(\"job group id\", \"read all files and print the schema\")\n",
    "\n",
    "#Speicherorte der Daten festlegen \n",
    "#Daniel\n",
    "#folder_Temperature = '/Users/danielwentsch/Desktop/BigData/Data/02_airtemperature/'\n",
    "#folder_Solar = '/Users/danielwentsch/Desktop/BigData/Data/04_solar/'\n",
    "#Mario\n",
    "folder_Temperature = '/home/mario/dwd_data/temperatur_only_10_stations/'\n",
    "folder_Solar = '/home/mario/dwd_data/solar_only_10_stations/'\n",
    "\n",
    "#Lufttemperatur\n",
    "#Daniel\n",
    "df_Temperatur = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"inferSchema\", \"false\").csv(folder_Temperature+'*.txt')\n",
    "#Sonnenscheindauer\n",
    "#Daniel\n",
    "df_Solar = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"inferSchema\", \"false\").csv(folder_Solar+'*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Temperatur.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Solar.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nächste Schritte: \n",
    "1. Datenstruktur verstehen \n",
    "2. Daten bearbeiten und in einen finalen DF schreiben \n",
    "-> Zusammenfassen der Daten auf eine Station und einen TimeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATIONS_ID: string (nullable = true)\n",
      " |-- MESS_DATUM: string (nullable = true)\n",
      " |--   QN: string (nullable = true)\n",
      " |-- PP_10: string (nullable = true)\n",
      " |-- TT_10: string (nullable = true)\n",
      " |-- TM5_10: string (nullable = true)\n",
      " |-- RF_10: string (nullable = true)\n",
      " |-- TD_10: string (nullable = true)\n",
      " |-- eor: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Temperatur.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus diesem Datensatz benötigen wir die Spalten StationsID und MESS_Datum (Zeitstempel) TT_10 (Luftemperatur in 2m Höhe) und TM5_10 (Luftemperatur in 2cm Höhe) und PP_10(Luftdruck)\n",
    "Ändern der Datentypen von TT_10, TM5_10 und PP_10 in float, MESS_Datum in Timestamp ändern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+---------+-------------+--------------+\n",
      "|STATIONS_ID|MESS_DATUM         |Luftdruck|Temperatur_2m|Temperatur_5cm|\n",
      "+-----------+-------------------+---------+-------------+--------------+\n",
      "|1766       |2010-01-01 00:00:00|989.7    |-1.3         |-1.8          |\n",
      "|1766       |2010-01-01 00:10:00|989.7    |-1.3         |-1.8          |\n",
      "|1766       |2010-01-01 00:20:00|989.8    |-1.3         |-1.8          |\n",
      "+-----------+-------------------+---------+-------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bearbeiten der Struktur in Gewünschtes Format \n",
    "#Datentypen bearbeiten \n",
    "sc.setJobGroup(\"job group id\", \"select only columns that we need, change column type, rename columns\")\n",
    "df_Temperatur = df_Temperatur\\\n",
    "    .withColumn('STATIONS_ID',df_Temperatur.STATIONS_ID.cast(IntegerType()))\\\n",
    "    .withColumn('TM5_10',df_Temperatur.TM5_10.cast(FloatType()))\\\n",
    "    .withColumn('PP_10',df_Temperatur.PP_10.cast(FloatType()))\\\n",
    "    .withColumn('TT_10',df_Temperatur.TT_10.cast(FloatType()))\\\n",
    "    .withColumn(\"MESS_DATUM\",to_timestamp(\"MESS_DATUM\", \"yyyyMMddHHmm\"))\n",
    "\n",
    "#Spalten umbennen\n",
    "df_Temperatur = df_Temperatur\\\n",
    "    .withColumnRenamed('TT_10','Temperatur_2m')\\\n",
    "    .withColumnRenamed('TM5_10','Temperatur_5cm')\\\n",
    "    .withColumnRenamed('PP_10','Luftdruck')\n",
    "\n",
    "#Daten droppen\n",
    "df_Temperatur = df_Temperatur.drop('  QN','RF_10','TD_10','eor')\n",
    "\n",
    "sc.setJobGroup(\"job group id\", \"remove -999 values\")\n",
    "df_Temperatur = df_Temperatur.filter((df_Temperatur.Luftdruck != -999.0))\n",
    "df_Temperatur = df_Temperatur.filter((df_Temperatur.Temperatur_2m != -999.0))\n",
    "df_Temperatur = df_Temperatur.filter((df_Temperatur.Temperatur_5cm != -999.0))\n",
    "df_Temperatur.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11252290"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Temperatur.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATIONS_ID: string (nullable = true)\n",
      " |-- MESS_DATUM: string (nullable = true)\n",
      " |--   QN: string (nullable = true)\n",
      " |-- DS_10: string (nullable = true)\n",
      " |-- GS_10: string (nullable = true)\n",
      " |-- SD_10: string (nullable = true)\n",
      " |-- LS_10: string (nullable = true)\n",
      " |-- eor: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Solar.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus diesem Datensatz benötigen wir die Spalten StationsID und MESS_Datum (Zeitstempel), SD_10 (10 min-Summe der Sonnenscheindauer)\n",
    "Ändern der Datentypen von SD_10 in float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-----------------+\n",
      "|STATIONS_ID|MESS_DATUM         |Sonnenscheindauer|\n",
      "+-----------+-------------------+-----------------+\n",
      "|        232|2010-01-01 00:00:00|0.0              |\n",
      "|        232|2010-01-01 00:10:00|0.0              |\n",
      "|        232|2010-01-01 00:20:00|0.0              |\n",
      "+-----------+-------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Datentypen bearbeiten\n",
    "sc.setJobGroup(\"job group id\", \"select only columns that we need, change column type, rename columns\")\n",
    "df_Solar = df_Solar\\\n",
    "    .withColumn('SD_10',df_Solar.SD_10.cast(FloatType()))\\\n",
    "    .withColumn(\"MESS_DATUM\",to_timestamp(\"MESS_DATUM\", \"yyyyMMddHHmm\"))\n",
    "#Daten droppen \n",
    "df_Solar = df_Solar.drop('  QN','DS_10','GS_10','LS_10','eor')\n",
    "#Spalte umbennen\n",
    "df_Solar = df_Solar.withColumnRenamed('SD_10','Sonnenscheindauer')\n",
    "df_Solar = df_Solar.filter((df_Solar.Sonnenscheindauer != -999.0))\n",
    "df_Solar.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Solar.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die beiden Datensätze in die passende Struktur gebracht wurden, können Sie mit einem Join verbunden werden. \n",
    "Welchen Join? \n",
    "Da für die Auswertung des Spruches, für jede Station und jeden TimeStamp Daten von Solar und Temperature benötigt werden, müssen diese auch von beiden vorhanden sein. \n",
    "Daher wird der Inner Join gewählt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join der DF\n",
    "sc.setJobGroup(\"job group id\", \"join solar and temperature\")\n",
    "df_Final = df_Temperatur.join(df_Solar, (df_Temperatur.STATIONS_ID == df_Solar.STATIONS_ID) & (df_Temperatur.MESS_DATUM == df_Solar.MESS_DATUM),\"inner\").select(df_Temperatur['*'],df_Solar.Sonnenscheindauer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATIONS_ID: integer (nullable = true)\n",
      " |-- MESS_DATUM: timestamp (nullable = true)\n",
      " |-- Luftdruck: float (nullable = true)\n",
      " |-- Temperatur_2m: float (nullable = true)\n",
      " |-- Temperatur_5cm: float (nullable = true)\n",
      " |-- Sonnenscheindauer: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Final.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Final.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf der Basis dieser Datentabelle kann nun die Auswertung zur Bauernregel erfolgen. \n",
    "Diese Tabelle kann natürlich noch um weitere Wetterdaten erweitert werden, damit andere Bauernregeln oder andere Wettersimulationen durchgeführt werden können."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bauernregel 1:\n",
    "\n",
    "\"Ist der Januar hell und weiß, wird der Sommer sicher heiß\"\n",
    "1. DF anlegen, welcher alle Kombinationen von Station ID und Jahre besitzt\n",
    "2. Daten für Januar und Sommer erstellen\n",
    "3. Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATIONS_ID: integer (nullable = true)\n",
      " |-- MESS_DATUM: timestamp (nullable = true)\n",
      " |-- Luftdruck: float (nullable = true)\n",
      " |-- Temperatur_2m: float (nullable = true)\n",
      " |-- Temperatur_5cm: float (nullable = true)\n",
      " |-- Sonnenscheindauer: float (nullable = true)\n",
      " |-- Jahr: integer (nullable = true)\n",
      " |-- Monat: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DF aus dem df_Final erzeugen welcher alle Kombinationen der StationsIDs, Monate und Jahre enthält\n",
    "#Neue Spalte Jahr hinzufügen\n",
    "df = df_Final\n",
    "df  = df.withColumn(\"Jahr\", year(\"MESS_DATUM\"))\n",
    "df  = df.withColumn(\"Monat\", month(\"MESS_DATUM\"))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = false)\n",
      " |-- STATIONS_ID: integer (nullable = true)\n",
      " |-- Jahr: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Kombinationen =  df.withColumn(\"ID\",concat_ws('','Jahr','STATIONS_ID'))\n",
    "df_Kombinationen = df_Kombinationen.select(\"ID\",'STATIONS_ID','Jahr')\n",
    "df_Kombinationen = df_Kombinationen.dropDuplicates([\"ID\"])\n",
    "df_Kombinationen.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:06:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----+\n",
      "|ID      |STATIONS_ID|Jahr|\n",
      "+--------+-----------+----+\n",
      "|20151766|1766       |2015|\n",
      "|20161766|1766       |2016|\n",
      "|20183166|3166       |2018|\n",
      "+--------+-----------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_Kombinationen.show(3,False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro Jahr sind nur die Temperaturen von 21. Juni bis 23. September und die Sonnenscheindauer im Januar wichtig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zu DF df_Kombinationen eine neue Spalte hinzufügen, welche die Summe an Sonnenstunden pro StationsID und Jahr enthält \n",
    "df_Final_Solar_Grouped = df.filter((df.Monat == 12)).groupBy('STATIONS_ID','Jahr','Monat').mean('Sonnenscheindauer')\n",
    "df_Final_Solar_Grouped = df_Final_Solar_Grouped.withColumnRenamed('avg(Sonnenscheindauer)','Sonnenscheindauer')\n",
    "df_Kombinationen = df_Kombinationen.join(df_Final_Solar_Grouped,(df_Kombinationen.STATIONS_ID == df_Final_Solar_Grouped.STATIONS_ID)&(df_Kombinationen.Jahr == df_Final_Solar_Grouped.Jahr )).select(df_Kombinationen['*'],df_Final_Solar_Grouped.Sonnenscheindauer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final_Temperatur_Grouped = df.filter((df.Monat == 7)|(df.Monat == 8)).groupBy('STATIONS_ID','Jahr').mean('Temperatur_2m')\n",
    "df_Final_Temperatur_Grouped = df_Final_Temperatur_Grouped.withColumnRenamed('avg(Temperatur_2m)','Temperatur_2m')\n",
    "df_Kombinationen = df_Kombinationen.join(df_Final_Temperatur_Grouped,(df_Kombinationen.STATIONS_ID == df_Final_Temperatur_Grouped.STATIONS_ID)&(df_Kombinationen.Jahr == df_Final_Temperatur_Grouped.Jahr )).select(df_Kombinationen['*'],df_Final_Temperatur_Grouped.Temperatur_2m)\n",
    "df_Kombinationen = df_Kombinationen.sort('Jahr')\n",
    "df_Kombinationen = df_Kombinationen.sort('STATIONS_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = false)\n",
      " |-- STATIONS_ID: integer (nullable = true)\n",
      " |-- Jahr: integer (nullable = true)\n",
      " |-- Sonnenscheindauer: double (nullable = true)\n",
      " |-- Temperatur_2m: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Kombinationen.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=>  (4 + 5) / 9][Stage 28:>   (0 + 3) / 9][Stage 31:>   (0 + 0) / 8]9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:11:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:==> (5 + 4) / 9][Stage 28:>   (0 + 4) / 9][Stage 31:>   (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:11:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===>(7 + 2) / 9][Stage 28:>   (0 + 6) / 9][Stage 31:>   (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:11:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===>(8 + 1) / 9][Stage 28:>   (0 + 7) / 9][Stage 31:>   (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:11:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                 (0 + 8) / 9][Stage 31:>                 (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:11:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>   (0 + 8) / 9][Stage 31:>   (0 + 0) / 8][Stage 34:>   (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:11:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:11:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:12:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:12:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:12:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:12:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:12:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+--------------------+------------------+\n",
      "|ID     |STATIONS_ID|Jahr|Sonnenscheindauer   |Temperatur_2m     |\n",
      "+-------+-----------+----+--------------------+------------------+\n",
      "|2015232|232        |2015|0.025358198403370797|20.47743055197714 |\n",
      "|2012232|232        |2012|0.013385596887166921|18.321281366931494|\n",
      "|2011232|232        |2011|0.007090725703999453|17.31738350874207 |\n",
      "+-------+-----------+----+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_Kombinationen.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:==> (5 + 4) / 9][Stage 60:>   (0 + 4) / 9][Stage 63:>   (0 + 0) / 8]9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:16:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:==> (6 + 3) / 9][Stage 60:>   (0 + 5) / 9][Stage 63:>   (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:16:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:===>(8 + 1) / 9][Stage 60:>   (0 + 7) / 9][Stage 63:>   (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:16:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                 (0 + 8) / 9][Stage 63:>                 (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:16:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>   (0 + 8) / 9][Stage 63:>   (0 + 0) / 8][Stage 66:>   (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 03:16:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/02/03 03:16:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Korrelation zwischen Sonnenschein und Durschsnittstemperatur berechnen\n",
    "corr_Spruch = df_Kombinationen.stat.corr('Sonnenscheindauer','Temperatur_2m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07188381758199253\n"
     ]
    }
   ],
   "source": [
    "print(corr_Spruch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bauernregel 2:\n",
    "\n",
    "„Wenn's im Dezember nicht wintert, sommert's im Juni auch nicht.“\n",
    "\n",
    "Hierbei handelt es sich im Prinzip um die entgegengesetzte Regel zu der vorherigen:\n",
    "Im Juni wird es nicht warm, wenn im Dezember kein richtiger Winter war.\n",
    "Es stimmt, dass die These zu 65 Prozent eintrifft. Andersrum, wenn es also im Juni nicht „sommert“, wird es im Dezember nicht „wintern“,\n",
    "stimmt die Bauernregel aber nicht. Warum das so ist, weiß keiner so genau.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need months June and Decemeber\n",
    "sc.setJobGroup(\"job group id\", \"filter only june and december\")\n",
    "df = df_Final\n",
    "df = df.filter((month(\"MESS_DATUM\") == 6) | (month(\"MESS_DATUM\") == 12))\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobGroup(\"job group id\", \"convert timestamp into month and year\")\n",
    "df = df.select(\"STATIONS_ID\", year(\"MESS_DATUM\").alias(\"year\"),month(\"MESS_DATUM\").alias(\"month\"), \"Temperatur_2m\")\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+--------------------+\n",
      "|year|month|STATIONS_ID|  avg(Temperatur_2m)|\n",
      "+----+-----+-----------+--------------------+\n",
      "|1994|    6|        867|  16.606396293308617|\n",
      "|2004|   12|        867|-0.42678571584529085|\n",
      "|2012|    6|       1303|  14.924861110029397|\n",
      "|1998|   12|       1766|   3.179009858163334|\n",
      "|1996|   12|       1766| -1.5861970200912785|\n",
      "|1995|    6|       5440|   14.32541666428248|\n",
      "|2007|   12|        232|  0.3754928317204732|\n",
      "|2011|   12|        232|   3.489516128774225|\n",
      "|1993|   12|       5440|   3.264300160396236|\n",
      "|2019|    6|        232|   19.16817130015956|\n",
      "|2020|   12|       5100|   4.743279568033166|\n",
      "|1996|    6|       5440|  16.966481355155043|\n",
      "|2014|    6|       3166|  14.149143521211766|\n",
      "|2014|    6|       1766|  15.994351854589251|\n",
      "|2015|    6|       5109|  14.535252531249114|\n",
      "|2011|    6|        891|  15.910046307466649|\n",
      "|2001|    6|       1303|  14.092196877835606|\n",
      "|2007|   12|       5100|  1.9235439051199692|\n",
      "|2015|    6|       5440|  16.600995370414523|\n",
      "|2018|    6|       5440|  17.747569444334065|\n",
      "+----+-----+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calculate average temperature for each year+month+stations_id\n",
    "sc.setJobGroup(\"job group id\", \"calculate average temperature for each year+month+stations_id\")\n",
    "df = df.groupBy(\"year\", \"month\", \"STATIONS_ID\").avg(\"Temperatur_2m\")\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 106:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+--------------------+\n",
      "|year|month|STATIONS_ID|  avg(Temperatur_2m)|\n",
      "+----+-----+-----------+--------------------+\n",
      "|2004|   12|        867|-0.42678571584529085|\n",
      "|1998|   12|       1766|   3.179009858163334|\n",
      "|1996|   12|       1766| -1.5861970200912785|\n",
      "|2007|   12|        232|  0.3754928317204732|\n",
      "|2011|   12|        232|   3.489516128774225|\n",
      "|1993|   12|       5440|   3.264300160396236|\n",
      "|2020|   12|       5100|   4.743279568033166|\n",
      "|2007|   12|       5100|  1.9235439051199692|\n",
      "|2014|   12|       5440|  2.4165098560359795|\n",
      "|2019|   12|        232|  2.2346326188788512|\n",
      "|2009|   12|        891|  1.5916890661769603|\n",
      "|2017|   12|        891|  4.5894041186996395|\n",
      "|1995|   12|       1766|  -1.556287943330346|\n",
      "|2013|   12|       1766|   5.322535843062665|\n",
      "|1999|   12|       3166| -0.6046184778798642|\n",
      "|1995|   12|        867|  -1.564560928765858|\n",
      "|2004|   12|        891|   3.748443536922569|\n",
      "|2012|   12|       1303|  4.3271462884363086|\n",
      "|2020|   12|       1766|   5.141733873657228|\n",
      "|2003|   12|       3166| 0.20620519732455572|\n",
      "+----+-----+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc.setJobGroup(\"job group id\", \"new dataframe with only december\")\n",
    "df2 = df.filter(df.month == 12)\n",
    "#df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------------+---------+----------+\n",
      "|year_december|month_december|STATIONS_ID|temperature_december|year_june|month_june|\n",
      "+-------------+--------------+-----------+--------------------+---------+----------+\n",
      "|         2004|            12|        867|-0.42678571584529085|     2005|         6|\n",
      "|         1998|            12|       1766|   3.179009858163334|     1999|         6|\n",
      "|         1996|            12|       1766| -1.5861970200912785|     1997|         6|\n",
      "|         2007|            12|        232|  0.3754928317204732|     2008|         6|\n",
      "|         2011|            12|        232|   3.489516128774225|     2012|         6|\n",
      "|         1993|            12|       5440|   3.264300160396236|     1994|         6|\n",
      "|         2020|            12|       5100|   4.743279568033166|     2021|         6|\n",
      "|         2007|            12|       5100|  1.9235439051199692|     2008|         6|\n",
      "|         2014|            12|       5440|  2.4165098560359795|     2015|         6|\n",
      "|         2019|            12|        232|  2.2346326188788512|     2020|         6|\n",
      "|         2009|            12|        891|  1.5916890661769603|     2010|         6|\n",
      "|         2017|            12|        891|  4.5894041186996395|     2018|         6|\n",
      "|         1995|            12|       1766|  -1.556287943330346|     1996|         6|\n",
      "|         2013|            12|       1766|   5.322535843062665|     2014|         6|\n",
      "|         1999|            12|       3166| -0.6046184778798642|     2000|         6|\n",
      "|         1995|            12|        867|  -1.564560928765858|     1996|         6|\n",
      "|         2004|            12|        891|   3.748443536922569|     2005|         6|\n",
      "|         2012|            12|       1303|  4.3271462884363086|     2013|         6|\n",
      "|         2020|            12|       1766|   5.141733873657228|     2021|         6|\n",
      "|         2003|            12|       3166| 0.20620519732455572|     2004|         6|\n",
      "+-------------+--------------+-----------+--------------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "sc.setJobGroup(\"job group id\", \"adding additional month and year columns\")\n",
    "df2 = df2.withColumnRenamed('avg(Temperatur_2m)', 'temperature_december')\n",
    "df2 = df2.withColumnRenamed('year', 'year_december')\n",
    "df2 = df2.withColumnRenamed('month', 'month_december')\n",
    "df2 = df2.withColumn('year_june', df2.year_december + 1)\n",
    "df2 = df2.withColumn('month_june', lit(6))\n",
    "#df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 133:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------------+---------+----------+------------------+\n",
      "|year_december|month_december|STATIONS_ID|temperature_december|year_june|month_june|  temperature_june|\n",
      "+-------------+--------------+-----------+--------------------+---------+----------+------------------+\n",
      "|         1993|            12|        867|   2.357974910526119|     1994|         6|16.606396293308617|\n",
      "|         2011|            12|       1303|   5.188978491840036|     2012|         6|14.924861110029397|\n",
      "|         1994|            12|       5440|   3.384896769919023|     1995|         6| 14.32541666428248|\n",
      "|         2018|            12|        232|  2.9756272414058285|     2019|         6| 19.16817130015956|\n",
      "|         1995|            12|       5440| -0.9267697132402851|     1996|         6|16.966481355155043|\n",
      "|         2013|            12|       3166|   2.742562724210616|     2014|         6|14.149143521211766|\n",
      "|         2013|            12|       1766|   5.322535843062665|     2014|         6|15.994351854589251|\n",
      "|         2014|            12|       5109|  2.3267473103111365|     2015|         6|14.535252531249114|\n",
      "|         2010|            12|        891| -2.6403225815544524|     2011|         6|15.910046307466649|\n",
      "|         2000|            12|       1303|   5.097849463329627|     2001|         6|14.092196877835606|\n",
      "|         2014|            12|       5440|  2.4165098560359795|     2015|         6|16.600995370414523|\n",
      "|         2017|            12|       5440|  1.8029569865932094|     2018|         6|17.747569444334065|\n",
      "|         2018|            12|        891|   5.954233873310068|     2019|         6|18.213101862757295|\n",
      "|         1998|            12|       3166| -1.1100403452563425|     1999|         6|12.790605485124235|\n",
      "|         2008|            12|       3166| -0.6681899648947528|     2009|         6|12.312824073654633|\n",
      "|         2017|            12|       1303|  3.9217517983608987|     2018|         6|17.896527776011713|\n",
      "|         2003|            12|       1766|  3.3829749109220146|     2004|         6|15.713680543943688|\n",
      "|         2020|            12|       5440|  1.6949596777324663|     2021|         6|19.008611131597448|\n",
      "|         2016|            12|       3166|   0.895542114916321|     2017|         6|16.165694443495184|\n",
      "|         2002|            12|       5440|  1.6963709676538103|     2003|         6|21.047106479936176|\n",
      "+-------------+--------------+-----------+--------------------+---------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc.setJobGroup(\"job group id\", \"join two dataframes\")\n",
    "df2 = df2.join(df, (df2.year_june == df.year) & (df2.month_june == df.month) & (df2.STATIONS_ID == df.STATIONS_ID)).select(df2[\"*\"], df[\"avg(Temperatur_2m)\"])\n",
    "df2 = df2.withColumnRenamed('avg(Temperatur_2m)', 'temperature_june')\n",
    "#df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2159190300045076"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.setJobGroup(\"job group id\", \"calculate correlation\")\n",
    "df2.corr(\"temperature_december\", \"temperature_june\", method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/hdfs://192.168.199.80:9000/user/mario/output_files/10minutenwerte_only_100_result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
